#!/usr/bin/env python3

# I M P O R T   M O D U L E S 
import argparse
import socket
import ssl
import re
import select

# V A R I A B L E S
HTTP_VERSION = 'HTTP/1.1'
DEFAULT_SERVER = "proj5.3700.network"
DEFAULT_PORT = 443


# C R A W L E R   C L A S S
class Crawler:
    # CONSTRUCTOR
    def __init__(self, args):
        # socket
        self.count = 0
        self.s = None
        # command line vars
        self.server = args.server
        self.port = args.port
        self.username = args.username
        self.password = args.password
        # http header vars
        self.middle_token = None
        self.csrf_token = None
        self.session_id = None
        # functional vars
        self.flags = []
        self.links = {}

    # METHOD: craft GET request
    def get_request(self, addr):
        get = (f'GET {addr} {HTTP_VERSION}\r\n'
               f'Host: {self.server}\r\n'
               f'Connection: Keep-Alive\r\n\r\n')
        print("GET Request to %s:%d" % (self.server, self.port))
        # print(get)
        return get

    # METHOD: parse provided response for http header vars
    def parse_response(self, response):
        # search for session id
        self.session_id = re.search(r'sessionid=([^;]*)', response)
        if self.session_id is not None:
            self.session_id = self.session_id[1]
            print("session_id = %s" % self.session_id)

        # search for csrf token
        self.csrf_token = re.search(r'csrftoken=([^;]*)', response)
        if self.csrf_token is not None:
            self.csrf_token = self.csrf_token[1]
            print("csrf = %s" % self.csrf_token)

        # search for csrf middleware token
        self.middle_token = re.search(r'name="csrfmiddlewaretoken" value="\s*([^\n\r]*)', response)
        if self.middle_token is not None:
            self.middle_token = self.middle_token[1][:-2]
            print("middlewaretoken = %s" % self.middle_token)

    # METHOD: craft POST request
    def post_request(self, addr):
        # f'&csrfmiddlewaretoken={self.middle_token}'
        body = (f'username={self.username}&password={self.password}'
                f'&next=/fakebook/')
        post = (f'POST {addr} HTTP/1.1\r\n'
                f'Host: {self.server}\r\n'
                f'Cookie: sessionid={self.session_id}; csrftoken={self.csrf_token}\r\n'
                f'Accept-Encoding: gzip\r\n'
                f'Content-Type: application/x-www-form-urlencoded\r\n'
                f'Content-Length: {len(body)}\r\n'
                f'\r\n'
                f'{body}\r\n\r\n')
        return post

    # METHOD: navigate to a new page
    def goto(self, addr):
        # send GET request and recv response
        self.s.send(self.get_request(addr).encode('ascii'))
        get_data = self.s.recv(4000).decode('ascii')

        # send POST request and recv response
        self.s.send(self.post_request(addr).encode('ascii'))
        post_data = self.s.recv(4000).decode('ascii')

        # isolate status code
        status = re.search(r'HTTP/1.1 (\d{1})', post_data).group(1)
        print("status code= %s" % status)

        # delegate based on status code
        if status == '2':
            print("status code= %s" % status)
            # ...
        elif status == '3':
            print("status code= %s" % status)
            # search page for flags

            # find all links of the page

            # loop that navigates to all the pages

        elif status == '4':
            # abandon the url
            return
        elif status == '5':
            # retry goto
            self.goto(addr)
        else:
            print("ERROR: unrecognized error code. relaunching.")
            self.s.close()
            self.run()
            return

    # METHOD: execute crawler class
    def run(self):
        self.setup()

        # create initial GET request and send
        self.s.send(self.get_request('/accounts/login/').encode('ascii'))

        get_data = self.receive_data()
        # print(get_data)
        self.parse_response(get_data)

        # determine if necessary vars found
        if self.csrf_token is None or self.session_id is None or self.middle_token is None:
            self.count += 1
            print("ERROR: csrf_token and/or session_id and/or middle_token not found.")
            print("Reattempting initial GET request for the " + str(self.count) + " time .\n")
            self.s.close()
            self.run()
            return

        # # create POST request and send
        # self.s.send(self.post_request('/accounts/login/').encode('ascii'))
        #
        # # recv response and print
        # post_data = self.s.recv(4000).decode('ascii')
        # print("\nRESPONSE:\n")
        # print(post_data)
        # self.parse_response(post_data)
        #
        # # isolate redirect address and goto
        # addr = re.search(r'Location: ([^;]*)', post_data).group[1]
        # self.goto(self.s, addr)

        # close socket
        self.s.close()

    def receive_data(self):
        print("Receiving data")
        data = []
        while True:
            ready = select.select([self.s], [], [], 1.0)
            if ready[0]:
                chunk = self.s.recv(1024)
                if not chunk:
                    break
                data.append(chunk.decode('ascii'))

            return "".join(data)

    def setup(self):
        # setup socket, wrap, and connect
        self.s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        context = ssl.create_default_context()
        self.s.connect((self.server, self.port))
        self.s = context.wrap_socket(self.s, server_hostname=self.server)
        self.s.setblocking(0)


# M A I N   M E T H O D
if __name__ == "__main__":
    # setup arg parser
    parser = argparse.ArgumentParser(description='crawl Fakebook')
    parser.add_argument('-s', dest="server", type=str, default=DEFAULT_SERVER, help="The server to crawl")
    parser.add_argument('-p', dest="port", type=int, default=DEFAULT_PORT, help="The port to use")
    parser.add_argument('username', type=str, help="The username to use")
    parser.add_argument('password', type=str, help="The password to use")
    args = parser.parse_args()

    # setup crawler and execute
    sender = Crawler(args)
    sender.run()
