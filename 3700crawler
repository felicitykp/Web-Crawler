#!/usr/bin/env python3

# I M P O R T   M O D U L E S 
import argparse
import json
import socket
import ssl
import re

# V A R I A B L E S
HTTP_VERSION = 'HTTP/1.1'
DEFAULT_SERVER = "proj5.3700.network"
DEFAULT_PORT = 443


# C R A W L E R   C L A S S
class Crawler:
    # CONSTRUCTOR
    def __init__(self, args):
        # sock vars
        self.sock = None
        # command line vars
        self.server = args.server
        self.port = args.port
        self.username = args.username
        self.password = args.password
        # http header vars
        self.middle_token = None
        self.csrf_token = None
        self.session_id = None
        # functional vars
        self.flags = []
        self.visited = []
        self.to_visit = []

    # METHOD: craft GET request
    def get_request(self, path):
        get = (f'GET {path} {HTTP_VERSION}\r\n'
               f'Host: {self.server}\r\n'
               f'Cookie: csrftoken={self.csrf_token}; sessionid={self.session_id}\r\n'
               f'Connection: Keep-Alive\r\n\r\n')
        # print("GET Request to %s:%d" % (self.server, self.port))
        return get

    def initial_get_request(self, path):
        get = (f'GET {path} {HTTP_VERSION}\r\n'
               f'Host: {self.server}\r\n'
               f'Connection: Keep-Alive\r\n\r\n')
        # print("GET Request to %s:%d" % (self.server, self.port))
        print(get)
        return get

    # METHOD: parse provided response for http header vars
    def parse_response(self, response):
        # search for session id
        self.session_id = re.search(r'sessionid=([^;]*)', response)
        if self.session_id is not None:
            self.session_id = self.session_id[1]
            # print("session_id = %s" % self.session_id)

        # search for csrf token
        self.csrf_token = re.search(r'csrftoken=([^;]*)', response)
        if self.csrf_token is not None:
            self.csrf_token = self.csrf_token[1]
            # print("csrf = %s" % self.csrf_token)

        # search for csrf middleware token
        self.middle_token = re.search(r'name="csrfmiddlewaretoken" value="\s*([^\n\r]*)', response)
        if self.middle_token is not None:
            self.middle_token = self.middle_token[1][:-2]
            # print("middlewaretoken = %s" % self.middle_token)

    # METHOD: craft POST request
    def post_request(self, path):
        body = (f'username={self.username}&password={self.password}'
                f'&csrfmiddlewaretoken={self.middle_token}'
                f'&next=/fakebook/')
        post = (f'POST {path} {HTTP_VERSION}\r\n'
                f'Host: {self.server}\r\n'
                f'Cookie: sessionid={self.session_id}; csrftoken={self.csrf_token}\r\n'
                f'Accept-Encoding: gzip\r\n'
                f'Content-Type: application/x-www-form-urlencoded\r\n'
                f'Content-Length: {len(body)}\r\n'
                f'\r\n'
                f'{body}\r\n\r\n')
        # print("POST Request to %s:%d" % (self.server, self.port))
        return post

    # METHOD: navigate to a new page
    def goto(self, path):

        # send GET request and recv response
        self.sock.send(self.get_request(path).encode('ascii'))
        get_data = self.receive_data()

        # reload if page fails
        if get_data is None:
            # print("NO DATA for " + path + ". TRY AGAIN.")
            # print(get_data)
            self.goto(path)
            return

        # update that it has been visited
        self.visited.append(path)

        # isolate status code
        status = re.search(r'HTTP/1.1 (\d)', get_data).group(1)

        # delegate based on status code
        if status == '2':
            # print("Searching " + path + "...")
            self.search_page(get_data)

        elif status == '3':
            # HTTP Redirect
            new_location = re.search(r'Location:\s*([^\n\r]*)', get_data)[1]
            if new_location not in self.visited:
                print("NEW URL: " + new_location)
                self.to_visit.append(new_location)

        elif status == '4':
            # abandon the url
            print("Forbidden / Not Found")
        
        elif status == '5':
            # retry goto
            # print("5 - " + path)
            self.to_visit.append(path)

        else:
            print("ERROR: unrecognized error code. relaunching.")
            self.sock.close()
            self.run()
            return

    def setup(self):
        # setup socket, wrap, and connect
        self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        context = ssl.create_default_context()
        self.sock.connect((self.server, self.port))
        self.sock = context.wrap_socket(self.sock, server_hostname=self.server)

    def search_page(self, page_data):
        # FIND SECRET FLAGS
        # <h2 class='secret_flag' style="color:red">FLAG: 64-characters-of-random-alphanumerics</h2>

        # look for any flags on page
        for flag in re.findall(r'FLAG: (.*?)</h2>', page_data):
            print("FLAG FOUND: " + flag)
            self.flags.append(flag)

        # find all urls
        links = re.findall(r'href="/fakebook/(.*?)"', page_data)
        for link in links:
            link = "/fakebook/" + link
            if link not in self.visited and link not in self.to_visit:
                self.to_visit.append(link)
                # self.goto(link)

    def receive_data(self):
        data = self.sock.recv(4096)
        try:
            content_length = int(re.search(r'Content-Length: (\d+)', data.decode('ascii')).group(1))

            while len(data) < content_length:
                data += self.sock.recv(4096)

            return data.decode('ascii')
        except AttributeError:
            # print(data)
            return None

    # METHOD: execute crawler class
    def run(self):
        # setup socket, wrap, and connect
        self.setup()

        # send GET request for fakebook page and recv response
        self.sock.send(self.initial_get_request('/accounts/login/').encode('ascii'))
        get_data = self.receive_data()
        self.parse_response(get_data)

        # determine if necessary vars found
        if self.csrf_token is None or self.session_id is None or self.middle_token is None:
            print("ERROR: csrf_token and/or session_id and/or middle_token not found.")
            print("Reattempting initial GET request.\n")
            self.sock.close()
            self.run()
            return

        # create POST request to log in and recv response
        self.sock.send(self.post_request('/accounts/login/?next=/fakebook/').encode('ascii'))
        post_data = self.receive_data()
        self.parse_response(post_data)

        # isolate redirect address and goto
        new_location = re.search(r'Location:\s*([^\n\r]*)', post_data)[1]
        self.to_visit.append(new_location)

        try:
            # keep exploring the frontier until all flags found or all pages explored
            while len(self.to_visit) > 0 and len(self.flags) < 5:
                self.goto(self.to_visit.pop())
        except RecursionError:
            print(self.flags)

        # close socket
        self.sock.close()


# M A I N   M E T H O D
if __name__ == "__main__":
    # setup arg parser
    parser = argparse.ArgumentParser(description='crawl Fakebook')
    parser.add_argument('-s', dest="server", type=str, default=DEFAULT_SERVER, help="The server to crawl")
    parser.add_argument('-p', dest="port", type=int, default=DEFAULT_PORT, help="The port to use")
    parser.add_argument('username', type=str, help="The username to use")
    parser.add_argument('password', type=str, help="The password to use")
    args = parser.parse_args()

    # setup crawler and execute
    sender = Crawler(args)
    sender.run()
