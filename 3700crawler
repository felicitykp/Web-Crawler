#!/usr/bin/env python3

# I M P O R T   M O D U L E S 
import argparse
import socket
import ssl
import re

# V A R I A B L E S
DEFAULT_SERVER = "proj5.3700.network"
DEFAULT_PORT = 443

# C R A W L E R   C L A S S
class Crawler:
  # CONSTRUCTOR
  def __init__(self, args):
    self.server = args.server
    self.port = args.port
    self.username = args.username
    self.password = args.password


  # METHOD: execute crawler class
  def run(self):

    # setup socket, wrap, and connect
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    context = ssl.create_default_context()
    sock.connect((self.server, self.port))
    sock = context.wrap_socket(sock, server_hostname=self.server)

    # create intial GET request and send
    get = (f'GET /accounts/login/ HTTP/1.1\r\n'
           f'Host: {self.server}\r\n'
           f'Connection: Keep-Alive\r\n\r\n')
    print("Request to %s:%d" % (self.server, self.port))
    print(get)
    sock.send(get.encode('ascii'))

    # recv response and print
    getdata = sock.recv(4000).decode('ascii')
    print("Response:\n%s" % getdata)

    # search for session id
    sessionid = re.search(r'sessionid=([^;]*)', getdata).group(1)
    print("sessionid= %s" % sessionid)

    # search for csrf token
    csrf = re.search(r'csrftoken=([^;]*)', getdata).group(1)
    print("csrftoken= %s" % csrf)

    # try to find csrf middleware token - relaunch if not found
    try:
      mid = re.search(r'name="csrfmiddlewaretoken" value="\s*([^\n\r]*)', getdata).group(1)[:-2]
      print("csrfmiddlewaretoken= %s" % mid)
    except:
      self.run()
      return

    # create POST request and send
    body = (f'username={self.username}&password={self.password}'
            f'&csrfmiddlewaretoken={mid}'
            f'&next=/fakebook/')
    post = (f'POST /accounts/login/ HTTP/1.1\r\n'
            f'Host: {self.server}\r\n'
            f'Cookie: sessionid={sessionid}; csrftoken={csrf}\r\n'
            f'Accept-Encoding: gzip\r\n'
            f'Content-Type: application/x-www-form-urlencoded\r\n'
            f'Content-Length: {len(body)}\r\n'
            f'\r\n'
            f'{body}\r\n\r\n')
    sock.send(post.encode('ascii'))

    # recv response and print
    postdata = sock.recv(4000).decode('ascii')
    print("Response:\n%s" % postdata)

    # isolate status code
    status = re.search(r'HTTP/1.1 (\d{3})', postdata).group(1)
    print("status code= %s" % status)    




    # then have to do the actual flag searching ...

    # close socket
    sock.close()

# M A I N   M E T H O D
if __name__ == "__main__":

  # setup arg parser
  parser = argparse.ArgumentParser(description='crawl Fakebook')
  parser.add_argument('-s', dest="server", type=str, default=DEFAULT_SERVER, help="The server to crawl")
  parser.add_argument('-p', dest="port", type=int, default=DEFAULT_PORT, help="The port to use")
  parser.add_argument('username', type=str, help="The username to use")
  parser.add_argument('password', type=str, help="The password to use")
  args = parser.parse_args()

  # setup crawler and execute
  sender = Crawler(args)
  sender.run()
